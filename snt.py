from datetime import datetime
import os
from openpyxl import load_workbook
import re
import sys
import concurrent.futures
from sinotrans.core import FileParser,ExcelProcessor,EmlParser
from sinotrans.utils import Logger,GlobalThreadPool, ProgressManager

# # é…ç½®è·¯å¾„å‚æ•°ï¼šos.path.abspath(__file__)
# # æ‰“åŒ…æ›¿æ¢å¯åŠ¨è·¯å¾„ä¸ºï¼šroot_path3 = os.path.dirname(os.path.realpath(sys.executable))
# timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
# CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))   
# TARGET_PATH = os.path.join(CURRENT_DIR, "target")
# CONFIG_PATH = os.path.join(CURRENT_DIR, "conf")
# DEBUG_PATH = os.path.join(CURRENT_DIR, "logs")
# # æ–‡ä»¶è·¯å¾„é…ç½®
# RESOURCE_FILE = os.path.join(CURRENT_DIR, "input_data.xlsx")
# TEMPLATE_FILE = os.path.join(CURRENT_DIR, "template.xlsx")
# TARGET_FILE = os.path.join(TARGET_PATH, f"output_result_{timestamp}.xlsx")
# MAPPING_FILE = os.path.join(CONFIG_PATH, "mapping.txt")
# FIXED_MAPPING_FILE = os.path.join(CONFIG_PATH, "fixed_mapping.txt")
# EMAIL_MAPPING_FILE = os.path.join(CONFIG_PATH, "email_mapping.txt")
# CONTAINER_TYPES = ["20GP", "40GP", "40HQ"]
# PO_NAME="POå·"
# CONTAINER_TYPE_NAME="é›†è£…ç®±ç±»å‹"
# é…ç½®è·¯å¾„å‚æ•°ï¼šos.path.abspath(__file__)
# æ‰“åŒ…æ›¿æ¢å¯åŠ¨è·¯å¾„ä¸ºï¼šroot_path3 = os.path.dirname(os.path.realpath(sys.executable))
timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))  
TARGET_PATH = os.path.join(CURRENT_DIR, "target")
CONFIG_PATH = os.path.join(CURRENT_DIR, "conf")
RESPONSE_PATH = os.path.join(CURRENT_DIR, "res")
SNT_PATH = os.path.join(CURRENT_DIR, "snt")
REPORT_PATH = os.path.join(CURRENT_DIR, "report")
DEBUG_PATH = os.path.join(CURRENT_DIR, "logs")

SHEET_CONFIG_FILE = os.path.join(CONFIG_PATH, "sheet_config.txt")

FIXED_MAPPING_FILE = os.path.join(CONFIG_PATH, "fixed_mapping.txt")
BC4_REPORT_MAPPING_FILE = os.path.join(CONFIG_PATH, "bc4_report_mapping.txt")
PENDING_PO_MAPPING_FILE = os.path.join(CONFIG_PATH, "pending_po_mapping.txt")
RESPONSE_MAPPING_FILE = os.path.join(CONFIG_PATH, "response_mapping.txt")

TEMPLATE_FILE = os.path.join(CURRENT_DIR, "template.xlsx")
TARGET_FILE = os.path.join(TARGET_PATH, f"output_result_{timestamp}.xlsx")

REQUIRED_FIELDS=[
    "folder",
    "po",
    "lot",
]
Logger(debug_path=DEBUG_PATH)

FileParser.ensure_directories_exist(directories = [
    TARGET_PATH,
    CONFIG_PATH,
    SNT_PATH,
    RESPONSE_PATH,
])
GlobalThreadPool.initialize(
    max_workers=16,
    thread_name_prefix='AutoTOThreadPool',
    initializer=lambda: Logger.debug("AutoTOThreadPool initialized"),
    initargs=()
)
# é¢„å®šä¹‰é…ç½®
DEFAULT_FALLBACK_SHEET = "Sheet1"  # é»˜è®¤å›é€€å·¥ä½œè¡¨

def validate_and_get_sheets(wb, file_path, sheet_names):
    """éªŒè¯å·¥ä½œç°¿å¹¶è¿”å›æœ‰æ•ˆå·¥ä½œè¡¨æ˜ å°„"""
    # æ£€æŸ¥å¿…éœ€å·¥ä½œè¡¨æ˜¯å¦å­˜åœ¨
    existing_sheets = set(wb.sheetnames)
    missing_sheets = set(sheet_names) - existing_sheets
    if missing_sheets:
        raise ValueError(f"æ–‡ä»¶ {file_path} ç¼ºå¤±å¿…éœ€å·¥ä½œè¡¨: {', '.join(missing_sheets)}")

    # è·å–æœ‰æ•ˆå·¥ä½œè¡¨ï¼ˆæ•°æ®ä¸ä¸ºç©ºæ—¶ä¼˜å…ˆï¼Œå¦åˆ™ä½¿ç”¨å›é€€è¡¨ï¼‰
    sheet_map = {}
    for sheet_name in sheet_names:
        ws = wb[sheet_name]
        # æ£€æŸ¥æ•°æ®æ˜¯å¦ä¸ºç©ºï¼ˆè‡³å°‘æœ‰ä¸€ä¸ªéç©ºå•å…ƒæ ¼ï¼‰
        has_data = any(
            cell.value not in (None, "")
            for row in ws.iter_rows(min_row=1, max_row=1)  # æ£€æŸ¥é¦–è¡Œ
            for cell in row
        )
        
        if not has_data:
            Logger.warning(f"å·¥ä½œè¡¨ {sheet_name} æ•°æ®ä¸ºç©ºï¼Œå°è¯•å›é€€åˆ°{DEFAULT_FALLBACK_SHEET}")
            if DEFAULT_FALLBACK_SHEET in wb.sheetnames:
                fallback_ws = wb[DEFAULT_FALLBACK_SHEET]
                if any(cell.value for cell in next(fallback_ws.iter_rows())):
                    sheet_map[sheet_name] = fallback_ws
                else:
                    raise ValueError(f"å›é€€è¡¨{DEFAULT_FALLBACK_SHEET}ä¹Ÿä¸ºç©º")
            else:
                raise ValueError(f"æ— æœ‰æ•ˆæ•°æ®ä¸”æ‰¾ä¸åˆ°å›é€€è¡¨{DEFAULT_FALLBACK_SHEET}")
        else:
            sheet_map[sheet_name] = ws
    
    return sheet_map
# def process_fields(row_data, global_po_mapping):
#     """å¤åˆ¶æºè¡Œæ•°æ®ï¼Œå¹¶ç»“åˆé‚®ä»¶ä¸­é›†è£…ç®±ç±»å‹åŠä¸ªæ•°ï¼Œç”Ÿæˆå¤šä¸ªæ–°è¡Œ"""
#     try:
#         po = str(row_data[PO_NAME])
#         if po not in global_po_mapping:
#             return []
#         rows_to_add = []
#         quantity = 1
#         container_str = global_po_mapping[po].pop(CONTAINER_TYPE_NAME, None)
#         if container_str is None:
#             raise ValueError(f"âŒ æœªæ‰¾åˆ°ä¸ {po} ç›¸å…³è”çš„é›†è£…ç®±ç±»å‹ï¼")
#         container_types = container_str.split(",")
#         for type_str in container_types:
#             match = re.search(r'(\d+)$', type_str)
#             if match:
#                 quantity = int(match.group(1))
#                 type_part = type_str[:match.start(1)]
#                 type = type_part[:-1].replace("HC", "HQ").replace("GC", "GP").replace("STD", "GP")
#             for _ in range(quantity):
#                 new_row = row_data.copy()
#                 new_row[CONTAINER_TYPE_NAME] = type
#                 rows_to_add.append(new_row)
#     except Exception as e:
#         print(f"âŒ æ ¹æ®åŸè¡Œæ•°æ®ï¼Œç”Ÿæˆæ–°è¡Œæ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
#         raise
#     return rows_to_add
def map_fields(report_rows, response_rows, snt_rows, fixed_mapping, snt_mapping, bc4_report_mapping, response_mapping):
    """æ ¹æ®æ¨¡æ¿åˆ—é¡ºåºå¯¹ç”Ÿæˆçš„æ–°è¡Œæ•°æ®è¿›è¡Œæ’åº"""
    mapped_rows = []
    for row in report_rows:
        mapped_row = {}
        mapped_row.update(ExcelProcessor.fixed_mapping(fixed_mapping))
        # mapped_row.update(ExcelProcessor.column_mapping(row, snt_mapping))
        mapped_row.update(ExcelProcessor.column_mapping(row, bc4_report_mapping))
        # mapped_row.update(ExcelProcessor.column_mapping(row, response_mapping))
        mapped_rows.append(mapped_row)
    for row in response_rows:
        mapped_row = {}
        mapped_row.update(ExcelProcessor.fixed_mapping(fixed_mapping))
        mapped_row.update(ExcelProcessor.column_mapping(row, response_mapping))
        mapped_rows.append(mapped_row)
    for row in snt_rows:
        mapped_row = {}
        mapped_row.update(ExcelProcessor.fixed_mapping(fixed_mapping))
        mapped_row.update(ExcelProcessor.column_mapping(row, snt_mapping))
        mapped_rows.append(mapped_row)
    return mapped_rows
def process_resource_row(report_rows, response_rows, snt_rows, ns_output, fixed_mapping, snt_mapping, bc4_report_mapping, response_mapping):
    try:
        """å¤„ç†æºè¡Œæ•°æ®ï¼Œç”Ÿæˆæ–°è¡Œæ•°æ®å¹¶è¿”å›"""
        mapped_rows = map_fields(report_rows, response_rows, snt_rows, fixed_mapping, snt_mapping, bc4_report_mapping, response_mapping)
        sorted_rows = ExcelProcessor.sort_generated_rows(mapped_rows, ns_output)
        return sorted_rows
    except Exception as e:
        Logger.error(f"âŒ å¤„ç†æºè¡Œæ•°æ®å¤±è´¥: {str(e)}")
        raise
def process_resource_data(ns_output, snt_data_generator, report_data_generator, response_data_generator, progress, fixed_mapping, snt_mapping, bc4_report_mapping, response_mapping):
    new_rows = [] 
    try:
        Logger.info("ğŸ“‹ æ­£åœ¨å¤„ç†èµ„æºæ•°æ®...")
        with GlobalThreadPool.get_executor() as executor:
            futures =[]
            # åŒæ—¶éå†ä¸‰ä¸ªç”Ÿæˆå™¨ï¼Œæ¯æ¬¡å–ä¸€è¡Œä¼ å…¥ process_resource_row
            for snt_row, report_row, response_row in zip(snt_data_generator, report_data_generator, response_data_generator):
                future = executor.submit(
                    process_resource_row,
                    snt_row, report_row, response_row, ns_output,
                    fixed_mapping, snt_mapping, bc4_report_mapping, response_mapping
                )
                futures.append(future)
        progress.close()
        # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆï¼Œè®¾ç½®è¶…æ—¶æ—¶é—´
        done, not_done = concurrent.futures.wait(futures, timeout = 60)

        for future in futures:
            # å¦‚æœæŸäº›çº¿ç¨‹æŠ›å‡ºå¼‚å¸¸ï¼Œåœ¨è°ƒç”¨ future.result() æ—¶ä»ä¼šè§¦å‘å¼‚å¸¸ã€‚
            result = future.result()
            if result:
                new_rows.extend(result)
        Logger.info(f"âœ… æ‰«æåˆ°{len(futures)}è¡Œéç©ºæ•°æ®ï¼Œç”Ÿæˆ {len(new_rows)} è¡Œæ•°æ®")
        return new_rows
    except Exception as e:
        Logger.error(f"âŒ å¤„ç†èµ„æºæ•°æ®å¤±è´¥: {str(e)}")
        raise

def main():
    try:
        # è¯»å–æ˜ å°„å…³ç³»ï¼šsheer_config,pending_po_map,response_map,bc4_report_map
        sheet_names = FileParser.parse_conf(SHEET_CONFIG_FILE,',')
        fixed_mapping = FileParser.parse_mapping_dict(FIXED_MAPPING_FILE,':', '|', ',', '=')   # æ¨¡æ¿å€¼æ˜ å°„
        snt_mapping = FileParser.parse_mapping_dict_of_list(PENDING_PO_MAPPING_FILE,':', '|', ',', '=')
        response_mapping = FileParser.parse_mapping_dict(RESPONSE_MAPPING_FILE,':', '|', ',', '=')
        bc4_report_mapping = FileParser.parse_mapping_dict(BC4_REPORT_MAPPING_FILE,':', '|', ',', '=')
        Logger.info("âœ… è¯»å–æ˜ å°„æ–‡ä»¶æˆåŠŸï¼")
    except Exception as e:
        Logger.error(f"âŒ æ˜ å°„æ–‡ä»¶è¯»å–å¤±è´¥: {str(e)}")
        return 
    try:
        # è·å–sntã€æŠ¥æ–‡ã€ä¸šåŠ¡è¡¨çš„æ–‡ä»¶ååˆ—è¡¨
        snt_files = FileParser.read_files(SNT_PATH, [".xlsx",".xls"])
        report_files = FileParser.read_files(REPORT_PATH, [".xlsx",".xls"])
        response_files = FileParser.read_files(RESPONSE_PATH, [".xlsx",".xls"])
        Logger.info("âœ… è·å–sntã€æŠ¥æ–‡ã€ä¸šåŠ¡å›å¤çš„æ–‡ä»¶æˆåŠŸï¼")
    except Exception as e:
        Logger.error(f"âŒ è·å–sntã€æŠ¥æ–‡ã€ä¸šåŠ¡å›å¤çš„æ–‡ä»¶å¤±è´¥: {str(e)}")
        return 
    
    # TODO æ‰¹é‡ï¼Œéœ€è¦æ–‡ä»¶åçš„è®¾ç½®
    # try:
    #     # æ ¹æ®æ˜ å°„æ–‡ä»¶ä¸­çš„è¯»å–è§„åˆ™ï¼Œæå–è£…ç®±è®¡åˆ’ã€èˆ±å•å¯¹åº”å­—æ®µå€¼
    #     # to_files = parse_excel_files(to_files, to_mapping)
    #     excel_processor = ExcelProcessor()
    #     snt_file_content_map = excel_processor.parse_excel_files(files=snt_files, map=clp_map, progress=None, key_field_name=None)
    #     report_file_content_map = excel_processor.parse_excel_files(files=report_files, map=to_map, progress=None, key_field_name=None)
    #     Logger.info("âœ… æå–è£…ç®±è®¡åˆ’ã€èˆ±å•å¯¹åº”å­—æ®µå€¼æˆåŠŸï¼")
    # except Exception as e:
    #     Logger.error(f"âŒ æå–è£…ç®±è®¡åˆ’ã€èˆ±å•å¯¹åº”å­—æ®µå€¼å¤±è´¥: {str(e)}")
    #     return 
    try:
        # æ£€æŸ¥å¤šä¸ªExcelæ–‡ä»¶æ˜¯å¦åŒ…å«æŒ‡å®šçš„æ‰€æœ‰å·¥ä½œè¡¨ä¸”æ•°æ®ä¸ä¸ºç©º
        ExcelProcessor.check_excel_sheets(snt_files + response_files, sheet_names)
        # è·å–æ–°å·¥ä½œç°¿å’Œè¾“å‡ºå·¥ä½œè¡¨
        nf_output = FileParser.create_newfile_by_template(TEMPLATE_FILE, TARGET_FILE, list("feedback"))
        Logger.info("âœ… åˆ›å»ºæ¨¡æ¿æ–‡ä»¶")
        # ä»…è¯»å–æºæ•°æ®çš„å€¼/è¡¨å¤´
        Logger.info("ğŸ“‹ å¼€å§‹è¯»å–æºæ•°æ®......")
        # å› ä¸ºä¸æ˜¯æ‰¹é‡æ‰€ä»¥ä»…è¯»å–ç¬¬ä¸€ä¸ªæ–‡ä»¶ï¼Œä½œä¸ºsnt-
        input_workbooks = {
            "snt": load_workbook(snt_files[0], read_only=True),
            "report": load_workbook(report_files[0], read_only=True),
            "response": load_workbook(response_files[0], read_only=True)
        }
         # å»ºç«‹å·¥ä½œè¡¨æ˜ å°„å…³ç³»
        sheet_mapping = []
        for file_type, wb in input_workbooks.items():
            for sheet_name in wb.sheetnames:
                sheet_mapping.append((
                    wb[sheet_name],  # è¾“å…¥å·¥ä½œè¡¨
                    nf_output[sheet_name],  # è¾“å‡ºå·¥ä½œè¡¨
                    file_type  # æ–‡ä»¶ç±»å‹æ ‡è¯†
                ))

        Logger.info("âœ… æ‰€æœ‰è¾“å…¥æ–‡ä»¶éªŒè¯é€šè¿‡ï¼Œè¯»å–æºæ•°æ®æˆåŠŸï¼")
    except Exception as e:
        Logger.error(f"âŒ è·å–æ•°æ®å¤±è´¥: {str(e)}")
        if os.path.exists(TARGET_FILE):
            os.remove(TARGET_FILE)
            Logger.error("âŒ è·å–æ•°æ®å¤±è´¥ï¼Œå·²åˆ é™¤ç›®æ ‡æ–‡ä»¶ã€‚")
        return 
    try:
        progress = ProgressManager()
        for input_ws, output_ws, file_type in sheet_mapping:
            # ä½¿ç”¨ç”Ÿæˆå™¨é€è¡Œå¤„ç†ï¼Œé‡‡ç”¨ç”Ÿæˆå™¨æ¨¡å¼é¿å…ä¸€æ¬¡æ€§åŠ è½½æ‰€æœ‰æ•°æ®åˆ°å†…å­˜ä¸­
            data_generator = ExcelProcessor.excel_row_generator(
                input_ws,
                file_type,
                progress,
                required_columns=REQUIRED_FIELDS
            )
            new_rows = process_resource_data(output_ws, snt_data_generator, report_data_generator, response_data_generator, progress, fixed_mapping, snt_mapping, bc4_report_mapping, response_mapping)
            list(map(lambda row: output_ws.append(row), new_rows))
        progress.close()
        Logger.info("âœ… å¤„ç†å®Œæˆï¼")
    except Exception as e:
        Logger.error(f"âŒ æºæ•°æ®å¤„ç†å¤±è´¥: {str(e)}")
        if os.path.exists(TARGET_FILE):
            os.remove(TARGET_FILE)
            Logger.debug("âŒ æºæ•°æ®å¤„ç†å¤±è´¥ï¼Œå·²åˆ é™¤ç›®æ ‡æ–‡ä»¶ã€‚")
        return 
    try:
        # list(map(lambda row: ns_output.append(row), new_rows))
        nf_output.save(TARGET_FILE)
        Logger.info(f"ğŸ‰ ç»“æœå·²ä¿å­˜è‡³: {TARGET_FILE}")
    except Exception as e:
        Logger.error(f"âŒ ç»“æœä¿å­˜å¤±è´¥: {str(e)}")
        if os.path.exists(TARGET_FILE):
            os.remove(TARGET_FILE)
            Logger.debug("âŒ ç»“æœä¿å­˜å¤±è´¥ï¼Œå·²åˆ é™¤ç›®æ ‡æ–‡ä»¶ã€‚")
        return

if __name__ == "__main__":
    main()
    input("Press Enter to exit...")