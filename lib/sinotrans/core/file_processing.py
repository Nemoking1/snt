from openpyxl import load_workbook, Workbook
from sinotrans.core.rule import Rule
from sinotrans.utils.logger import Logger
from typing import get_type_hints
from openpyxl import load_workbook
from deprecated import deprecated
from pathlib import Path
import pandas as pd
import time
import os

class FileParser:
    """
    æ–‡ä»¶å¤„ç†ç±»,è§£ææ˜ å°„è§„åˆ™ï¼Œåˆ›å»ºè¾“å‡ºæ–‡ä»¶,è¿”å›ï¼š
    {
    "src_field_name1":[rule1, rule2, ...],
    "src_field_name2":[rule1, rule2, ...],
    ...
    }
    """
    @staticmethod
    def read_files(folder_path, suffixes):
        """æ–‡ä»¶å¤¹ä¸‹å¯¹åº”åç¼€çš„æ–‡ä»¶ç»å¯¹è·¯å¾„åˆ—è¡¨"""
        xls_files = []
        for to_f in os.listdir(folder_path): 
            if to_f.startswith("~$"):
                continue
            file_suffix = os.path.splitext(to_f)[1].lower()
            if file_suffix in suffixes:
                xls_file = os.path.join(folder_path, to_f)
                xls_files.append(xls_file)

        return xls_files
    @staticmethod
    def ensure_directories_exist(directories):
        """
        ç¡®ä¿æ‰€æœ‰å¿…è¦çš„ç›®å½•å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»ºå®ƒä»¬
        """
        for directory in directories:
            if not os.path.exists(directory):
                os.makedirs(directory)

    def create_newfile_by_template(template_file, target_file, additional_columns=None):
        """
        ä½¿ç”¨ pandas å¤åˆ¶æ¨¡æ¿ä¸­æ‰€æœ‰ sheet çš„è¡¨å¤´ï¼Œå¹¶æ”¯æŒæ·»åŠ æ–°åˆ—
        è¿”å›ï¼šabsolute_path
        """
        try:
            # è¯»å–æ‰€æœ‰ sheet çš„ç¬¬ä¸€è¡Œï¼ˆè‡ªåŠ¨è¯†åˆ« .xls/.xlsxï¼‰
            file = pd.ExcelFile(template_file)
            all_dfs = {}

            for sheet_name in file.sheet_names:
                df = pd.read_excel(file, sheet_name=sheet_name, nrows=0)# è¯»å–ç¬¬ä¸€ä¸ªæ•°æ®è¡Œï¼Œå³å¯èƒ½è¯»ç¬¬äºŒè¡Œpd.read_excel(file, sheet_name=sheet_name, nrows=1)
                if additional_columns:
                    for col in additional_columns:
                        df[col] = None
                all_dfs[sheet_name] = df

            # ç¡®ä¿ä¿å­˜ä¸º .xlsx æ ¼å¼
            if not target_file.lower().endswith('.xlsx'):
                target_file += '.xlsx'

            # ä½¿ç”¨ ExcelWriter å†™å…¥å¤šä¸ª sheet
            with pd.ExcelWriter(target_file, engine='openpyxl') as writer:
                for sheet_name, df in all_dfs.items():
                    df.to_excel(writer, index=False, sheet_name=sheet_name)

            return target_file

        except Exception as e:
            raise RuntimeError(f"å¤„ç†å¤±è´¥: {str(e)}")
    @staticmethod
    def create_newfile_by_template_retryable(template_file, target_file, additional_columns=None, max_retries=3, retry_interval=5):
        """
        ä½¿ç”¨ pandas å¤åˆ¶æ¨¡æ¿ä¸­æ‰€æœ‰ sheet çš„è¡¨å¤´ï¼Œå¹¶æ”¯æŒæ·»åŠ æ–°åˆ—ï¼Œæ”¯æŒè‡ªå®šä¹‰é‡è¯•æ¬¡æ•°å’Œé‡è¯•é—´éš”ï¼Œé»˜è®¤é‡è¯•3æ¬¡
        è¿”å›ï¼šabsolute_path
        """
        for attempt in range(1, max_retries + 1):
            try:
                # è¯»å–æ‰€æœ‰ sheet çš„ç¬¬ä¸€è¡Œï¼ˆè‡ªåŠ¨è¯†åˆ« .xls/.xlsxï¼‰
                file = pd.ExcelFile(template_file)
            except Exception as e:
                Logger.debug(f"è¯»å–{template_file}æ–‡ä»¶å¤±è´¥ (å°è¯• {attempt}/{max_retries}): {e}")
                if attempt < max_retries:
                    Logger.debug(f"ç­‰å¾… {retry_interval} ç§’åé‡è¯•...")
                    time.sleep(retry_interval)
                else:
                    raise RuntimeError(f"æ— æ³•è®¿é—®æ–‡ä»¶: {template_file}") from e
            try:
                all_dfs = {}
                for sheet_name in file.sheet_names:
                    df = pd.read_excel(file, sheet_name=sheet_name, nrows=0)# è¯»å–ç¬¬ä¸€ä¸ªæ•°æ®è¡Œï¼Œå³å¯èƒ½è¯»ç¬¬äºŒè¡Œpd.read_excel(file, sheet_name=sheet_name, nrows=1)
                    if additional_columns:
                        for col in additional_columns:
                            df[col] = None
                    all_dfs[sheet_name] = df

                # ç¡®ä¿ä¿å­˜ä¸º .xlsx æ ¼å¼
                if not target_file.lower().endswith('.xlsx'):
                    target_file += '.xlsx'

                # ä½¿ç”¨ ExcelWriter å†™å…¥å¤šä¸ª sheet
                with pd.ExcelWriter(target_file, engine='openpyxl') as writer:
                    for sheet_name, df in all_dfs.items():
                        df.to_excel(writer, index=False, sheet_name=sheet_name)

                return target_file
            except Exception as e:
                raise RuntimeError(f"å¤„ç†å¤±è´¥: {str(e)}")
    @staticmethod
    def save_file_retryable(file, max_retries=3, retry_interval=5):
        """
        ä¿å­˜æ–‡ä»¶ï¼Œå¦‚æœå¤±è´¥ï¼Œé‡è¯•å¤šæ¬¡
        å‚æ•°ï¼š
        file: æ–‡ä»¶è·¯å¾„
        max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
        retry_interval: é‡è¯•é—´éš”æ—¶é—´
        """
        for attempt in range(1, max_retries + 1):
            try:
                output_wb = load_workbook(file)
                output_wb.save(file)
                Logger.info(f"{file}ä¿å­˜æˆåŠŸ")
                break
            except Exception as e:
                Logger.info(f"è¯»å–{file}æ–‡ä»¶å¤±è´¥ (å°è¯• {attempt}/{max_retries}): {e}")
                if attempt < max_retries:
                    Logger.info(f"ç­‰å¾… {retry_interval} ç§’åé‡è¯•...")
                    time.sleep(retry_interval)
                else:
                    raise RuntimeError(f"æ— æ³•è®¿é—®æ–‡ä»¶: {file}") from e
    @deprecated(reason="æ›´æ–°è‡³create_newfile_by_templateä½¿ç”¨æ–°çš„pandasè¿›è¡Œæ›´çµæ´»çš„æ–‡ä»¶å¤„ç†ï¼ˆæ”¯æŒxls)", version="1.2.0")
    def create_newfile_by_template_v1(template_file_name, target_file_name, column_names = None):
            """
            åˆ›å»ºæ–°æ–‡ä»¶ï¼Œå¹¶å¤åˆ¶æ¨¡æ¿è¡¨å¤´
            å¯é€‰ï¼šæ·»åŠ æ–°åˆ—
            """
            # åŠ è½½æ¨¡æ¿å¹¶è·å–è¡¨å¤´ï¼ˆç¬¬ä¸€è¡Œæ•°æ®ï¼‰
            header_row = next(load_workbook(template_file_name).active.iter_rows(max_row=1, values_only=True))  # æå–ç¬¬ä¸€è¡Œæ•°æ®
            # æ·»åŠ æ–°åˆ—
            header_row = list(header_row)
            if not column_names:
                header_row.extend(column_names)
            # åˆ›å»ºæ–°å·¥ä½œç°¿å¹¶å†™å…¥è¡¨å¤´
            new_wb = Workbook()
            new_sheet = new_wb.active
            new_sheet.append(header_row)
            
            new_wb.save(target_file_name)
            return new_wb
    @staticmethod
    def parse_rule(value, prefix_separator, condition_separator, key_value_separator):
        """
        è§£æ"æŒ‡å®šå•è¡Œ"ä¸­"æŒ‡å®šæ ¼å¼åˆ†éš”ç¬¦"çš„é”®å€¼å¯¹æ ¼å¼çš„å­—ç¬¦ä¸²ï¼Œå°†å…¶è§£ææˆï¼š
        Ruleå¯¹è±¡
        """
        # åˆå§‹åŒ–Ruleå¯¹è±¡
        rule = Rule(field_name=value.split('|')[0].strip())
        # è·å–Ruleå¯¹è±¡çš„å±æ€§ç±»å‹
        type_hints = get_type_hints(type(rule))
        # è§£æå‚æ•°é”®å€¼å¯¹
        if prefix_separator in value:
            # å…ˆå–æ¡ä»¶å­—ç¬¦ä¸²
            params_str = value.split(prefix_separator, 1)[1]
            # éå†æ¡ä»¶
            for param in params_str.split(condition_separator):
                # paramä¸è¦å»æ‰æœ«å°¾ç©ºæ ¼ï¼Œä¸ç„¶åˆ†éš”ç¬¦ä¸ºç©ºæ ¼çš„æ—¶å€™å°±ä¼šè¢«è¯¯åˆ ï¼
                param = param
                if key_value_separator not in param:
                    continue
                # åˆ†å‰²å½“å‰æ¡ä»¶ï¼Œæå–é”®å€¼å¯¹
                k, v = param.split(key_value_separator, 1)
                k = k.strip()
                # åˆ¤æ–­å±æ€§æ˜¯å¦å­˜åœ¨ï¼Œå­˜åœ¨åˆ™å°è¯•è½¬æ¢ç±»å‹å¹¶èµ‹å€¼
                if hasattr(rule, k):
                    attr_type = type_hints[k]
                    try:
                        converted_v = attr_type(v)
                        setattr(rule, k, converted_v)
                    except (TypeError, ValueError) as e:
                        raise ValueError(f"âŒ å‚æ•° {k} çš„å€¼ {v} æ— æ³•è½¬æ¢ä¸ºæ­£ç¡®ç±»å‹: {e}")
        return rule
    @staticmethod
    def parse_conf(file_name, splitter):
        """
        è§£æ"æŒ‡å®šæ–‡ä»¶"ä¸­"æŒ‡å®šæ ¼å¼åˆ†éš”ç¬¦"çš„é”®å€¼å¯¹æ ¼å¼çš„æ‰€æœ‰è¡Œï¼Œå°†å…¶è§£ææˆï¼š
        {name1,name2,name3}
        """
        with open(file_name, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if not line or splitter not in line:
                    return line
                values = line.split(splitter)
        return values
    @staticmethod
    def parse_mapping_dict(file_name, splitter, prefix_separator, condition_separator, key_value_separator):
        """
        è§£æ"æŒ‡å®šæ–‡ä»¶"ä¸­"æŒ‡å®šæ ¼å¼åˆ†éš”ç¬¦"çš„é”®å€¼å¯¹æ ¼å¼çš„æ‰€æœ‰è¡Œï¼Œå°†å…¶è§£ææˆï¼š
        {
        "src_field_name1":rule1,
        "src_field_name2":rule2,
        ...
        }
        """
        mapping = {}
        with open(file_name, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if not line or splitter not in line:
                    continue
                key, value = line.split(splitter, 1)
                rule = FileParser.parse_rule(value, prefix_separator, condition_separator, key_value_separator)
                mapping[key.strip()] = rule
        return mapping
    @staticmethod
    def parse_mapping_dict_of_list(file_name, splitter, prefix_separator, condition_separator, key_value_separator):
        """
        è§£æ"æŒ‡å®šæ–‡ä»¶"ä¸­"æŒ‡å®šæ ¼å¼åˆ†éš”ç¬¦"çš„é”®å€¼å¯¹æ ¼å¼çš„æ‰€æœ‰è¡Œï¼Œå°†å…¶è§£ææˆï¼š
        {
        "src_field_name1":[rule1, rule2, ...],
        "src_field_name2":[rule1, rule2, ...],
        ...
        }
        """
        mapping = {}
        with open(file_name, 'r', encoding='utf-8') as f:
            for line in f:
                # å»é™¤ç©ºç™½å­—ç¬¦
                line = line.strip()
                # æ ¹æ®splitteråˆ†éš”ç¬¦åˆ¤æ–­è¯¥è¡Œæ˜¯å¦æœ‰æ•ˆâ€”â€”é”®å€¼å¯¹æ ¼å¼ï¼Œå¦åˆ™ï¼Œè·³è¿‡
                if not line or splitter not in line:
                    continue
                # æ ¹æ®splitteråˆ†éš”ç¬¦ï¼Œè·å–é”®å€¼å¯¹
                key, value = line.split(splitter, 1)
                # æ˜ å°„å¯¹è±¡å­˜åœ¨ï¼Œåˆ™è¿½åŠ rule, å¦åˆ™ï¼Œæ–°å»º
                if key not in mapping:
                    mapping[key] = []
                rule = FileParser.parse_rule(value, prefix_separator, condition_separator, key_value_separator)
                mapping[key.strip()].append(rule)
        return mapping
    @staticmethod
    def file_generator(file_path, clp_file_content_map, to_file_content_map, progress, required_keys=None):
        """éå†æ–‡ä»¶å†…å®¹æ˜ å°„è¡¨ï¼Œç”Ÿæˆæœ‰æ•ˆæ–‡ä»¶ç»å¯¹è·¯å¾„åˆ—è¡¨çš„ç”Ÿæˆå™¨ï¼Œå¹¶æ£€æŸ¥æ–‡ä»¶åæ˜¯å¦å­˜åœ¨"""
        Logger.debug("ğŸ“‚ å¼€å§‹éå†æ–‡ä»¶å†…å®¹æ˜ å°„è¡¨")
        
        # è·å–æ‰€æœ‰å”¯ä¸€æ–‡ä»¶åï¼ˆåˆå¹¶ä¸¤ä¸ªæ˜ å°„è¡¨çš„keyï¼‰
        all_files = set(clp_file_content_map.keys()).union(set(to_file_content_map.keys()))
        
        progress.init_main_progress(len(all_files))
        for file_name in all_files:
            # æ›´æ–°è¿›åº¦
            progress.update()
            
            try:
                # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦åœ¨ä¸¤ä¸ªæ˜ å°„è¡¨ä¸­éƒ½å­˜åœ¨
                in_clp = file_name in clp_file_content_map
                in_to = file_name in to_file_content_map
                
                if not in_clp or not in_to:
                    Logger.debug(f"- è·³è¿‡æ— æ•ˆæ–‡ä»¶ï¼š{file_name}ï¼ˆèˆ±å•æ–‡ä»¶æˆ–clpæ–‡ä»¶ç¼ºå¤±ï¼‰")
                    continue
                    
                # æ„å»ºæ–‡ä»¶æ•°æ®å­—å…¸
                file_data = {
                    "file_name": file_name,
                    "in_clp": in_clp,
                    "in_to": in_to,
                    "clp_content": clp_file_content_map.get(file_name),
                    "to_content": to_file_content_map.get(file_name)
                }
                
                # å¿…å¡«å­—æ®µæ£€æŸ¥
                if required_keys:
                    missing_keys = [
                        key for key in required_keys 
                        if file_data["clp_content"].get(key) in (None, "") \
                        or file_data["to_content"].get(key) in (None, "")
                    ]
                    if missing_keys:
                        Logger.debug(f"è·³è¿‡æ— æ•ˆæ–‡ä»¶ï¼š{file_name}ï¼Œç¼ºå¤±å­—æ®µï¼š{', '.join(missing_keys)}")
                        continue
                
                # # æ•°æ®æ¸…æ´—ï¼šå­—ç¬¦ä¸²å»ç©ºæ ¼
                # for key, value in file_data.items():
                #     if isinstance(value, str):
                #         file_data[key] = value.strip()
                
                yield os.path.join(file_path, file_name)
                
            except Exception as e:
                Logger.error(f"âŒ æ–‡ä»¶ {file_name} å¤„ç†å¤±è´¥: {str(e)}")
                continue
    @staticmethod
    def write_rows_to_files(add_rows):
        """
        å°† add_rows ä¸­çš„æ•°æ®å†™å…¥å¯¹åº”çš„ Excel æ–‡ä»¶ä¸­ã€‚
        
        å‚æ•°:
            add_rows (dict): {æ–‡ä»¶å: éœ€è¦æ·»åŠ çš„è¡Œåˆ—è¡¨}
        """
        for file_path, rows in add_rows.items():
            try:
                if os.path.exists(file_path):
                    # å¦‚æœæ–‡ä»¶å­˜åœ¨ï¼ŒåŠ è½½ç°æœ‰å·¥ä½œç°¿
                    wb = load_workbook(file_path)
                else:
                    raise FileNotFoundError(f"æ–‡ä»¶ {file_path} ä¸å­˜åœ¨")

                ws = wb.active
                # å†™å…¥æ•°æ®è¡Œ
                for row in rows:
                    ws.append(list(row.values()))
                # ä¿å­˜æ–‡ä»¶
                wb.save(file_path)
                Logger.info(f"âœ… æ•°æ®å·²æˆåŠŸå†™å…¥æ–‡ä»¶: {file_path}")
            except Exception as e:
                Logger.error(f"âŒ å†™å…¥æ–‡ä»¶ {file_path} æ—¶å‡ºé”™: {str(e)}")
    @staticmethod
    def load_wordbook_retryable(file, sheet_name=None, max_retries=3, retry_interval=5):
        for attempt in range(1, max_retries + 1):
            try:
                output_wb = load_workbook(file)
                if sheet_name is None:
                    output_ws = output_wb.active
                else:
                    output_ws = output_wb[sheet_name]
                return output_wb, output_ws
            except Exception as e:
                Logger.info(f"è¯»å–{file}æ–‡ä»¶å¤±è´¥ (å°è¯• {attempt}/{max_retries}): {e}")
                if attempt < max_retries:
                    Logger.info(f"ç­‰å¾… {retry_interval} ç§’åé‡è¯•...")
                    time.sleep(retry_interval)
                else:
                    raise RuntimeError(f"æ— æ³•è®¿é—®æ–‡ä»¶: {file}") from e
