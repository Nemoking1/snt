from sinotrans.utils.progress_manager import ExcelProgressTracker
from sinotrans.utils.global_thread_pool import GlobalThreadPool
from sinotrans.utils.logger import Logger
from sinotrans.core.rule import Rule
from typing import Dict, List, Tuple
from openpyxl import load_workbook
from deprecated import deprecated
from zipfile import BadZipFile
from pathlib import Path
import concurrent.futures
import pandas as pd
import warnings
import traceback
import time
import xlrd
import os

class ExcelProcessor:
    DEFAULT_SPLITTER = '#'
    """
    Excelæ˜ å°„å…³ç³»å·¥å…·å¤„ç†ç±»
    """
    def __init__(self):
        return
        # self.mapping = mapping, mapping: Dict[str, Any], excel_path:str
        # self.excel_path = excel_path
    @staticmethod
    def sort_generated_rows(mapped_rows, headers):
        """æ ¹æ®æ¨¡æ¿åˆ—é¡ºåºï¼Œæ„å»ºæ’å¥½åºçš„æ–°è¡Œåˆ—è¡¨"""
        try:
            ordered_rows = [] 
            for row in mapped_rows:
                # æŒ‰æ¨¡æ¿åˆ—é¡ºåºæ„å»ºæ•°æ®
                ordered_row = [
                    row.get(header, None)
                    for header in headers
                ]
                ordered_rows.append(ordered_row)
            return ordered_rows
        except Exception as e:
            Logger.error(f"âŒ æ„å»ºæ–°è¡Œæ•°æ®å¤±è´¥: {str(e)}")
            raise
    @staticmethod
    def fixed_mapping(fixed_mapping):
        """æ ¹æ®å›ºå®šå­—æ®µæ˜ å°„ï¼Œå¡«å……åˆ°å¯¹åº”åˆ—"""
        mapped_row = {}
        try:
            for dest_col, rule in fixed_mapping.items():
                mapped_row[dest_col] = rule.field_name
            return mapped_row
        except Exception as e:
            Logger.error(f"âŒ fixed_mappingæ˜ å°„å¤±è´¥: {str(e)}")
            raise
    @staticmethod
    def column_mapping(row, column_mapping):
        """
        æ ¹æ®åŸè¡Œæ•°æ®ï¼Œç»“åˆå­—æ®µæ˜ å°„æ–‡ä»¶ï¼Œç”Ÿæˆæ–°è¡Œæ•°æ®
        å¯¹å½“å‰è¾“å…¥è¿›è¡Œmapæ˜ å°„ï¼Œæ˜ å°„åˆ°dest_nameï¼Œè¿”å›å­—å…¸{dest_name:value,......}
        """
        mapped_row = {}
        try:
            for src_col, rules in column_mapping.items():
                raw_value = row.get(src_col, None)
                for rule in rules:
                    if raw_value:
                        mapped_row[rule.field_name] = rule.map_action(raw_value)
                    if rule.considerEmpty:
                        mapped_row[rule.field_name] = raw_value
            return mapped_row
        except Exception as e:
            Logger.error(f"âŒ mappingæ˜ å°„å¤±è´¥: {str(e)}")
            raise
    @staticmethod
    def email_mapping(row, key_field, global_po_mapping, email_mapping):
        """
        æ ¹æ®emailæ˜ å°„å’Œ global_po_mapping, ç”Ÿæˆæ–°è¡Œæ•°æ®
        """
        mapped_row = {}
        try:
            # email_poå€¼æ˜ å°„, å¤„ç†ä»é‚®ä»¶ä¸­è·å–çš„å€¼â€”â€”global_po_mapping, åˆå¹¶é‚®ä»¶å­—æ®µæ•°æ®
            key = str(row[key_field])
            if key in global_po_mapping:
                for rules in email_mapping.values():
                    for rule in rules:
                        raw_value = global_po_mapping[key].get(rule.field_name)
                        mapped_row[rule.field_name] = rule.map_action(raw_value)
            return mapped_row
        except Exception as e:
            Logger.error(f"âŒ email_mappingæ˜ å°„å¤±è´¥: {str(e)}")
            raise
    @staticmethod
    def content_mapping(key, map_content, map):
        """
        æ ¹æ®mapå’Œ map_contenté”®å€¼å¯¹åˆé›†, ç”Ÿæˆæ–°è¡Œæ•°æ®
        """
        mapped_row = {}
        try:
            content = map_content.get(key)
            for key in content.keys():
                for rules in map.get(key):
                    for rule in rules:
                        raw_value = content.get(key)
                        mapped_row[key] = rule.map_action(raw_value)
            return mapped_row
        except Exception as e:
            Logger.error(f"âŒ mappingæ˜ å°„å¤±è´¥: {str(e)}")
            raise

    @staticmethod
    def excel_row_generator_skipping(rs_input, file_name, progress=None, 
                        required_columns=None, desc=None, strict_flag=True):
        """ä¼˜åŒ–åçš„è¡Œæ•°æ®ç”Ÿæˆå™¨ï¼ˆæ”¯æŒè¿ç»­ç©ºè¡Œ1000è¡Œæå‰ç»ˆæ­¢ï¼‰"""
        Logger.debug(f"ğŸ“‹ å¼€å§‹è§£ææ–‡ä»¶ {file_name}ï¼ˆå…±{rs_input.max_row}è¡Œï¼‰")
        headers = [cell.value for cell in rs_input[1]]
        
        # é¢„ç”Ÿæˆå¿…å¡«åˆ—æ£€æŸ¥å™¨
        required_check = None
        if required_columns:
            required_check = {
                col: headers.index(col) 
                for col in required_columns 
                if col in headers
            }

        # åˆå§‹åŒ–è¿ç»­ç©ºè¡Œè®¡æ•°å™¨
        MAX_CONSECUTIVE_EMPTY = 1000  # æœ€å¤§å…è®¸è¿ç»­ç©ºè¡Œæ•°
        empty_counter = 0
        
        for row_idx, row in enumerate(rs_input.iter_rows(min_row=2), start=2):
            # ç©ºè¡Œæ£€æµ‹
            row_data = {
                headers[idx]: cell.value.strip() if isinstance(cell.value, str) else cell.value
                for idx, cell in enumerate(row)
            }
            
            if all(v in (None, "") for v in row_data.values()):
                empty_counter += 1
                if empty_counter >= MAX_CONSECUTIVE_EMPTY:
                    Logger.debug(f"â¹ æ£€æµ‹åˆ°è¿ç»­{empty_counter}è¡Œç©ºè¡Œï¼Œæå‰ç»ˆæ­¢è¯»å–ï¼ˆä»ç¬¬{row_idx}è¡Œèµ·ï¼‰")
                    break  # ç›´æ¥ç»ˆæ­¢å¾ªç¯
                continue
            else:
                empty_counter = 0  # é‡åˆ°éç©ºè¡Œæ—¶é‡ç½®è®¡æ•°å™¨

            # å¿…å¡«åˆ—æ ¡éªŒé€»è¾‘ï¼ˆåŸæœ‰é€»è¾‘ä¿æŒä¸å˜ï¼‰
            if required_check:
                missing_cols = [
                    col for col, idx in required_check.items() 
                    if row_data.get(col) in (None, "")
                ]
                if strict_flag and missing_cols:
                    Logger.debug(f"ä¸¥æ ¼æ¨¡å¼è·³è¿‡ï¼ˆç¬¬{row_idx}è¡Œï¼‰ï¼Œç¼ºå¤±å­—æ®µï¼š{', '.join(missing_cols)}")
                    continue
                elif not strict_flag and len(missing_cols) == len(required_check):
                    Logger.debug(f"å®½æ¾æ¨¡å¼è·³è¿‡ï¼ˆç¬¬{row_idx}è¡Œï¼‰ï¼Œå…¨éƒ¨å¿…å¡«å­—æ®µç¼ºå¤±")
                    continue

            yield row_data

        Logger.debug(f"âœ… æ–‡ä»¶è§£æå®Œæˆï¼Œå®é™…å¤„ç†åˆ°ç¬¬{row_idx}è¡Œ")
    @staticmethod
    def excel_row_generator(rs_input, file_name, progress=None, required_columns=None, desc=None, strict_flag=True):
        """
        å¸¦ä¸¥æ ¼æ¨¡å¼æ§åˆ¶çš„è¡Œæ•°æ®ç”Ÿæˆå™¨
        å‚æ•°ï¼š
        rs_input: xlrd.sheet.Sheetå¯¹è±¡
        file_name: str, æ–‡ä»¶å
        progress: ExcelProgressTrackerå¯¹è±¡, è¿›åº¦ç®¡ç†å™¨ï¼Œå¯é€‰
        required_columns: list, å¿…å¡«åˆ—
        desc: str, è¿›åº¦æè¿°
        strict_flag: bool, ä¸¥æ ¼æ¨¡å¼æ˜¯å¦å¼€å¯
        """
        Logger.debug(f"ğŸ“‹ å¼€å§‹è§£ææ–‡ä»¶{file_name}")
        headers = [cell.value for cell in rs_input[1]]
        
        # é¢„å¤„ç†å¿…å¡«åˆ—ç´¢å¼•
        required_indices = []
        if required_columns:
            required_indices = [
                headers.index(col) 
                for col in required_columns 
                if col in headers
            ]
        if progress:
            progress.init_main_progress(desc=desc, total=rs_input.max_row - 1)
        for row_idx, row in enumerate(rs_input.iter_rows(min_row=2), start=2):
            if progress:
                progress.update()  # ä¿æŒè¿›åº¦æ›´æ–°
            
            try:
                row_data = {
                    headers[idx]: cell.value.strip() if isinstance(cell.value, str) else cell.value
                    for idx, cell in enumerate(row)
                }

                # ç©ºè¡Œæ£€æµ‹
                if all(v in (None, "") for v in row_data.values()):
                    Logger.debug(f"- è·³è¿‡å…¨ç©ºè¡Œï¼ˆç¬¬{row_idx}è¡Œï¼‰")
                    continue

                # å¿…å¡«åˆ—æ ¡éªŒé€»è¾‘
                if required_indices:
                    missing_cols = [
                        headers[idx] 
                        for idx in required_indices 
                        if row_data.get(headers[idx]) in (None, "")
                    ]

                    # ä¸¥æ ¼æ¨¡å¼ï¼šå­˜åœ¨ç¼ºå¤±å³è·³è¿‡
                    if strict_flag:
                        if missing_cols:
                            Logger.debug(f"ä¸¥æ ¼æ¨¡å¼è·³è¿‡ï¼ˆç¬¬{row_idx}è¡Œï¼‰ï¼Œç¼ºå¤±å­—æ®µï¼š{', '.join(missing_cols)}")
                            continue
                    # å®½æ¾æ¨¡å¼ï¼šä»…å½“å…¨éƒ¨ç¼ºå¤±æ—¶è·³è¿‡
                    else:
                        if len(missing_cols) == len(required_indices):
                            Logger.debug(f"å®½æ¾æ¨¡å¼è·³è¿‡ï¼ˆç¬¬{row_idx}è¡Œï¼‰ï¼Œå…¨éƒ¨å¿…å¡«å­—æ®µç¼ºå¤±")
                            continue
                        elif missing_cols:
                            Logger.debug(f"å®½æ¾æ¨¡å¼ä¿ç•™ï¼ˆç¬¬{row_idx}è¡Œï¼‰ï¼Œéƒ¨åˆ†ç¼ºå¤±å­—æ®µï¼š{', '.join(missing_cols)}")

                yield row_data

            except Exception as e:
                Logger.error(f"âŒ ç¬¬{row_idx}è¡Œæ•°æ®è§£æå¤±è´¥: {str(e)}")
                continue
    def _process_common(self, file_path: str, worksheet, map: Dict[str, List[Rule]], is_xlsx: bool) -> Tuple[str, dict]:
        """æ–‡ä»¶åï¼Œ{ç›®çš„æ®µåï¼šç›®çš„æ®µå€¼}"""
        filename_no_ext = os.path.splitext(os.path.basename(file_path))[0]
        dict_map = {}

        # ç»Ÿä¸€è·å–è¡Œåˆ—èŒƒå›´ï¼ˆå…¼å®¹ä¸åŒåº“çš„ç´¢å¼•æ–¹å¼ï¼‰
        if is_xlsx:
            row_range = range(1, worksheet.max_row + 1)  # openpyxlä»1å¼€å§‹åˆ°max_row
            col_range = range(1, worksheet.max_column + 1)
        else:
            row_range = range(worksheet.nrows)  # xlrdä»0å¼€å§‹åˆ°nrows-1
            col_range = range(worksheet.ncols)

        # åŒé‡å¾ªç¯éå†æ‰€æœ‰å•å…ƒæ ¼
        for row_idx in row_range:
            for col_idx in col_range:
                # ç»Ÿä¸€è·å–å•å…ƒæ ¼å€¼
                try:
                    cell_value = worksheet.cell(row_idx, col_idx).value if is_xlsx \
                        else worksheet.cell_value(row_idx, col_idx)
                except Exception as e:
                    Logger.error(f"è¯»å–å•å…ƒæ ¼é”™è¯¯ @ è¡Œ{row_idx} åˆ—{col_idx}: {str(e)}")
                    continue

                if cell_value in map:
                    for rule in map[cell_value]:
                        values = []
                        offset = 0
                        try:
                            # ç¡®å®šç›®æ ‡ä½ç½®å’Œåç§»æ–¹å‘
                            if rule.dir == "row":
                                target_row = row_idx + 1
                                target_col = col_idx
                                max_limit = worksheet.max_row if is_xlsx else worksheet.nrows
                            elif rule.dir == "column":
                                target_row = row_idx
                                target_col = col_idx + 1
                                max_limit = worksheet.max_column if is_xlsx else worksheet.ncols
                            # readingModeä¼˜å…ˆçº§è¾ƒé«˜
                            if rule.readingMode:
                                if rule.readingMode == "readUntilBlank":
                                    while True:
                                        # è®¡ç®—å½“å‰è¯»å–ä½ç½®
                                        pos = (
                                            target_row + (offset if rule.dir == "row" else 0),
                                            target_col + (offset if rule.dir == "column" else 0)
                                        )
                                        
                                        # æ£€æŸ¥æ˜¯å¦è¶…å‡ºå·¥ä½œè¡¨èŒƒå›´
                                        if (rule.dir == "row" and pos[0] >= max_limit) or \
                                        (rule.dir == "column" and pos[1] >= max_limit):
                                            break
                                        
                                        # è·å–å•å…ƒæ ¼å€¼
                                        cell_value = worksheet.cell(*pos).value if is_xlsx else worksheet.cell_value(*pos)
                                        if cell_value is None or cell_value == "":
                                            break
                                        
                                        values.append(str(cell_value))
                                        offset += 1
                                    
                                    target_value = self.DEFAULT_SPLITTER.join(values) if values else ""
                            elif rule.count:
                                for i in range(rule.count):
                                    pos = (target_row + (offset if rule.dir == "row" else 0), 
                                        target_col + (offset if rule.dir == "column" else 0))
                                    
                                    if (rule.dir == "row" and pos[0] >= max_limit) or \
                                    (rule.dir == "column" and pos[1] >= max_limit):
                                        raise IndexError("åç§»è¶…å‡ºå·¥ä½œè¡¨èŒƒå›´")
                                    
                                    cell_value = worksheet.cell(*pos).value if is_xlsx else worksheet.cell_value(*pos)
                                    values.append(str(cell_value) if cell_value is not None else "")
                                    
                                    offset = offset + 1
                                target_value = self.DEFAULT_SPLITTER.join(values) if values else ""
                            else:
                                target_value = worksheet.cell(target_row, target_col).value if is_xlsx else worksheet.cell_value(target_row, target_col)
                            
                            dict_map[rule.field_name] = target_value
                        except Exception as ex:
                            raise ex
        return filename_no_ext, dict_map
    def _process_openpyxl(self, file_path: str, map: Dict[str, List[Rule]]) -> Tuple[str, dict]:
            """ å¤„ç† .xlsx æ–‡ä»¶ """
            src_wb = load_workbook(file_path)
            src_ws = src_wb.active
            Logger.debug(f"[xlsx] å·¥ä½œè¡¨åç§°: {src_wb.sheetnames}")
            return self._process_common(file_path, src_ws, map, is_xlsx=True)

    def _process_xlrd(self, file_path: str, map: Dict[str, List[Rule]]) -> Tuple[str, dict]:
        """ å¤„ç† .xls æ–‡ä»¶ """
        src_wb = xlrd.open_workbook(file_path)
        src_ws = src_wb.sheet_by_index(0)  # é»˜è®¤å–ç¬¬ä¸€ä¸ªå·¥ä½œè¡¨
        Logger.debug(f"[xls] å·¥ä½œè¡¨åç§°: {src_wb.sheet_names()}")
        return self._process_common(file_path, src_ws, map, is_xlsx=False)

    @deprecated(reason="æ›´æ–°è‡³process_single_excelä½¿ç”¨æ–°çš„pandasè¿›è¡Œæ›´çµæ´»çš„æ–‡ä»¶å¤„ç†ï¼ˆæ”¯æŒxls)", version="1.2.0")
    def process_single_excel_v1(self, file_path: str, map: Dict[str, List[Rule]]) -> Tuple[str, dict]:
        """
        æ”¯æŒå¤„ç† .xls å’Œ .xlsx æ–‡ä»¶çš„é€šç”¨å‡½æ•°
        è¿”å›ç»“æ„ï¼š(æ–‡ä»¶å, {"å­—æ®µå": "å­—æ®µå€¼"})
        """
        # æ ¹æ®æ‰©å±•åé€‰æ‹©è¯»å–æ–¹å¼
        ext = os.path.splitext(file_path)[1].lower()
        
        if ext == '.xlsx':
            return self._process_openpyxl(file_path, map)
        elif ext == '.xls':
            return self._process_xlrd(file_path, map)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {ext}")
    
    def parse_excel_files(self, files, map , file_type = None, progress = None, key_field_name = None):
        """
        è§£æexcelæ–‡ä»¶å¤¹ï¼Œè¿”å›ç»“æ„ï¼š
        {
        "key_field_value": {æ–‡ä»¶A k-vå­—å…¸},
        "key_field_value": {æ–‡ä»¶B k-vå­—å…¸},
        ...
        key_field_nameï¼šåŒºåˆ†æ–‡ä»¶çš„keyï¼Œé»˜è®¤ä¸º"filename"(ç›®å‰ä¸æ”¯æŒ)
        ç›®å‰ä»…æ”¯æŒæŒ‰ç…§æ˜ å°„ï¼Œè½¬æ¢æˆdes_field_nameçš„å­—å…¸ï¼Œkey_field_valueä¸ºæ–‡ä»¶å
        }
        """
        global_po_mapping = {}
        Logger.info(f"ğŸ“© å‘ç° {len(files)} å°{file_type}å¾…å¤„ç†æ–‡ä»¶")
        with GlobalThreadPool.get_executor() as executor:
            futures = [
                executor.submit(self.process_single_excel, filename, map)
                for filename in files
            ]
            
        for future in concurrent.futures.as_completed(futures):
            key_field_v, fields = future.result()
            if key_field_v:
                global_po_mapping[key_field_v] = fields
                Logger.debug(f"âœ… {key_field_v}ï¼šè§£æç»“æœï¼š{global_po_mapping[key_field_v]}")

        return global_po_mapping

    def process_single_excel(self, file_path: str, map: Dict[str, List[Rule]]) -> Tuple[str, dict]:
        """å¤„ç†Excelæ–‡ä»¶ï¼Œè¿”å›æ–‡ä»¶åå’Œå¤„ç†åçš„æ•°æ®"""
        filename_no_ext = os.path.splitext(os.path.basename(file_path))[0]
        
        # è¯»å–Excelæ–‡ä»¶ï¼ˆè·å–æ‰€æœ‰å·¥ä½œè¡¨åç§°ï¼‰
        with pd.ExcelFile(file_path) as excel:
            sheet_names = excel.sheet_names  # è·å–æ‰€æœ‰å·¥ä½œè¡¨åç§°
            Logger.debug(f"[Excel] å·¥ä½œè¡¨åç§°: {sheet_names}")
            
            # è¯»å–ç¬¬ä¸€ä¸ªå·¥ä½œè¡¨
            df = pd.read_excel(excel, sheet_name=sheet_names[0])
        
        dict_map = {}
        rows, columns = df.shape
        
        # éå†DataFrameçš„æ‰€æœ‰å•å…ƒæ ¼
        for row_idx in range(rows):
            for col_idx, col_name in enumerate(df.columns):
                cell_value = df.iloc[row_idx, col_idx]
                
                if pd.notna(cell_value) and str(cell_value) in map:
                    for rule in map[str(cell_value)]:
                        values = []
                        offset = 0
                        try:
                            # ç¡®å®šç›®æ ‡ä½ç½®å’Œåç§»æ–¹å‘
                            if rule.dir == "row":
                                target_row = row_idx + 1
                                target_col = col_idx
                                max_limit = rows
                            elif rule.dir == "column":
                                target_row = row_idx
                                target_col = col_idx + 1
                                max_limit = columns
                            else:
                                continue  # æ— æ•ˆæ–¹å‘ï¼Œè·³è¿‡
                                
                            # readingModeä¼˜å…ˆçº§è¾ƒé«˜
                            if hasattr(rule, 'readingMode') and rule.readingMode == "readUntilBlank":
                                while True:
                                    pos_row = target_row + (offset if rule.dir == "row" else 0)
                                    pos_col = target_col + (offset if rule.dir == "column" else 0)
                                    
                                    # æ£€æŸ¥è¾¹ç•Œ
                                    if (rule.dir == "row" and pos_row >= rows) or \
                                    (rule.dir == "column" and pos_col >= len(df.columns)):
                                        break
                                    
                                    try:
                                        cell_value = df.iloc[pos_row, pos_col]
                                    except IndexError:
                                        break
                                    
                                    if pd.isna(cell_value) or cell_value == "":
                                        break
                                    
                                    values.append(str(cell_value))
                                    offset += 1
                                
                                target_value = self.DEFAULT_SPLITTER.join(values) if values else ""
                            
                            # å¤„ç†å›ºå®šæ•°é‡çš„å•å…ƒæ ¼
                            elif hasattr(rule, 'count') and rule.count:
                                for i in range(rule.count):
                                    pos_row = target_row + (i if rule.dir == "row" else 0)
                                    pos_col = target_col + (i if rule.dir == "column" else 0)
                                    
                                    if (rule.dir == "row" and pos_row >= rows) or \
                                    (rule.dir == "column" and pos_col >= len(df.columns)):
                                        raise IndexError("åç§»è¶…å‡ºå·¥ä½œè¡¨èŒƒå›´")
                                    
                                    try:
                                        cell_value = df.iloc[pos_row, pos_col]
                                    except IndexError:
                                        cell_value = None
                                    
                                    values.append(str(cell_value) if pd.notna(cell_value) else "")
                                
                                target_value = self.DEFAULT_SPLITTER.join(values) if values else ""
                            
                            # é»˜è®¤æƒ…å†µï¼šè¯»å–å•ä¸ªå•å…ƒæ ¼
                            else:
                                try:
                                    target_value = df.iloc[target_row, target_col]
                                except IndexError:
                                    target_value = None
                            
                            # å­˜å‚¨ç»“æœ
                            if pd.notna(target_value):
                                dict_map[rule.field_name] = str(target_value)
                            else:
                                dict_map[rule.field_name] = ""
                        
                        except Exception as ex:
                            Logger.error(f"å¤„ç†å•å…ƒæ ¼({row_idx}, {col_idx})æ—¶å‡ºé”™: {str(ex)}")
                            continue
        
        return filename_no_ext, dict_map
    
    @staticmethod
    def get_checked_excel_sheets(file_paths: List[str], preset_sheets: List[str], default_fallback: str = "Sheet1"):
        """
        å¢å¼ºç‰ˆExcelæ–‡ä»¶æ ¡éªŒæ–¹æ³•
        
        Args:
            file_paths: éœ€è¦æ£€æŸ¥çš„Excelæ–‡ä»¶è·¯å¾„åˆ—è¡¨
            preset_sheets: å¿…é¡»å­˜åœ¨çš„é¢„è®¾å·¥ä½œè¡¨åˆ—è¡¨
            default_fallback: æ•°æ®ä¸ºç©ºæ—¶çš„é»˜è®¤å›é€€è¡¨å
        
        Returns:
            å­—å…¸ç»“æ„: {æ–‡ä»¶è·¯å¾„: {å·¥ä½œè¡¨å: å·¥ä½œè¡¨å¯¹è±¡}}
        
        Raises:
            FileNotFoundError: æ–‡ä»¶ä¸å­˜åœ¨
            ValueError: æ ¼å¼é”™è¯¯/è¡¨ç¼ºå¤±/æ•°æ®ç©ºä¸”æ— æ³•å›é€€
        """
        sheet_maps = {}

        for file_path in file_paths:
            # åŸºç¡€æ ¡éªŒ
            if not os.path.exists(file_path):
                raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            
            file_ext = os.path.splitext(file_path)[1].lower()
            if file_ext not in ('.xlsx', '.xlsm', '.xls'):
                raise ValueError(f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {file_ext}")

            wb = None
            xlrd_book = None
            try:
                # åŠ è½½å·¥ä½œç°¿
                if file_ext == '.xls':
                    # ä½¿ç”¨xlrdå¤„ç†æ—§æ ¼å¼
                    xlrd_book = xlrd.open_workbook(file_path)
                    sheet_names = xlrd_book.sheet_names()
                    get_sheet = lambda name: xlrd_book.sheet_by_name(name)
                else:
                    # ä½¿ç”¨openpyxlå¤„ç†æ–°æ ¼å¼
                    wb = load_workbook(file_path, read_only=True)
                    sheet_names = wb.sheetnames
                    get_sheet = lambda name: wb[name]

                # æ£€æŸ¥å¿…éœ€è¡¨å­˜åœ¨
                missing_sheets = set(preset_sheets) - set(sheet_names)
                if missing_sheets:
                    raise ValueError(f"æ–‡ä»¶ {file_path} ç¼ºå¤±å¿…éœ€è¡¨: {', '.join(missing_sheets)}")

                # æ„å»ºæœ‰æ•ˆè¡¨æ˜ å°„
                sheet_map = {}
                for req_sheet in preset_sheets:
                    try:
                        sheet = get_sheet(req_sheet)
                    except (KeyError, xlrd.biffh.XLRDError):
                        sheet = None

                    # æ£€æŸ¥æ•°æ®æœ‰æ•ˆæ€§
                    has_data = False
                    if sheet:
                        # ä¸åŒæ ¼å¼çš„æ•°æ®æ£€æŸ¥é€»è¾‘
                        if file_ext == '.xls':
                            has_data = sheet.nrows > 0 and any(
                                sheet.cell_value(row, col) not in (None, "")
                                for row in range(sheet.nrows)
                                for col in range(sheet.ncols)
                            )
                        else:
                            has_data = any(
                                cell.value not in (None, "")
                                for row in sheet.iter_rows(min_row=1, max_row=1)
                                for cell in row
                            )

                    # å¤„ç†ç©ºæ•°æ®å›é€€
                    if not has_data:
                        Logger.warning(f"[{file_path}] {req_sheet} æ•°æ®ä¸ºç©ºï¼Œå°è¯•å›é€€åˆ° {default_fallback}")
                        
                        try:
                            fallback_sheet = get_sheet(default_fallback)
                        except (KeyError, xlrd.biffh.XLRDError):
                            raise ValueError(f"å›é€€è¡¨ {default_fallback} ä¸å­˜åœ¨")

                        # éªŒè¯å›é€€è¡¨æ•°æ®
                        if file_ext == '.xls':
                            has_fallback_data = fallback_sheet.nrows > 0
                        else:
                            has_fallback_data = any(
                                cell.value for row in fallback_sheet.iter_rows()
                                for cell in row
                            )
                        
                        if not has_fallback_data:
                            raise ValueError(f"å›é€€è¡¨ {default_fallback} æ•°æ®ä¸ºç©º")
                        
                        sheet_map[req_sheet] = fallback_sheet
                    else:
                        sheet_map[req_sheet] = sheet

                sheet_maps[file_path] = sheet_map

            except Exception as e:
                # èµ„æºæ¸…ç†
                if wb: wb.close()
                if xlrd_book: xlrd_book.release_resources()
                raise RuntimeError(f"æ–‡ä»¶ {file_path} æ ¡éªŒå¤±è´¥: {str(e)}") from e

        return sheet_maps
    @staticmethod
    def get_excel_sheets(file_paths, preset_sheets=None, read_only=True, verbose=False):
        """
        è·å–Excelæ–‡ä»¶ä¸­æ‰€æœ‰å·¥ä½œè¡¨çš„å¥æŸ„
        
        :param file_paths: è¦å¤„ç†çš„Excelæ–‡ä»¶è·¯å¾„åˆ—è¡¨
        :param preset_sheets: é¢„è®¾å·¥ä½œè¡¨åç§°åˆ—è¡¨ï¼ˆç”¨äºæ ¡éªŒè­¦å‘Šï¼‰
        :param read_only: æ˜¯å¦ä½¿ç”¨åªè¯»æ¨¡å¼ä¼˜åŒ–å¤§æ–‡ä»¶åŠ è½½æ€§èƒ½
        :param verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†åŠ è½½æ—¥å¿—
        :return: åµŒå¥—å­—å…¸ç»“æ„ {æ–‡ä»¶ç»å¯¹è·¯å¾„: {å·¥ä½œè¡¨åç§°: å·¥ä½œè¡¨å¯¹è±¡}}
        """
        sheet_maps = {}
        preset_sheets = preset_sheets or []

        for file_path in file_paths:
            abs_path = str(Path(file_path).absolute())
            if verbose:
                Logger.info(f"â³ å¼€å§‹åŠ è½½æ–‡ä»¶: {abs_path}")

            try:
                # åŠ è½½å·¥ä½œç°¿ï¼ˆè‡ªåŠ¨å…³é—­æ–‡ä»¶å¥æŸ„ï¼‰
                with warnings.catch_warnings():
                    warnings.simplefilter("ignore")  # å¿½ç•¥openpyxlçš„è­¦å‘Š
                    wb = load_workbook(
                        filename=abs_path,
                        read_only=read_only,
                        data_only=True,
                        keep_links=False  # æé«˜åŠ è½½é€Ÿåº¦
                    )

                # æ”¶é›†æ‰€æœ‰å·¥ä½œè¡¨å¥æŸ„
                sheets = {}
                for sheet_name in wb.sheetnames:
                    sheet = wb[sheet_name]
                    sheets[sheet.title] = sheet
                    
                    # è®°å½•éé¢„è®¾sheetè­¦å‘Š
                    if preset_sheets and sheet.title not in preset_sheets:
                        msg = f"âš ï¸ æ£€æµ‹åˆ°éå¸¸è§„å·¥ä½œè¡¨ [{sheet.title}] åœ¨æ–‡ä»¶ {Path(abs_path).name}"
                        Logger.debug(msg)

                # ä¿ç•™å·¥ä½œç°¿å¼•ç”¨é¿å…è¢«GC
                sheets["_workbook"] = wb  
                sheet_maps[abs_path] = sheets
                
                if verbose:
                    Logger.info(f"âœ… æˆåŠŸåŠ è½½ {len(sheets)-1} ä¸ªå·¥ä½œè¡¨")

            except BadZipFile as e:
                error_msg = f"âŒ æ–‡ä»¶æŸåæ— æ³•æ‰“å¼€: {Path(abs_path).name} ({str(e)})"
                Logger.error(error_msg)
            except Exception as e:
                error_msg = f"âŒ åŠ è½½å¤±è´¥: {Path(abs_path).name}\n{traceback.format_exc()}"
                Logger.error(error_msg)

        return sheet_maps
    @staticmethod
    def load_excel_to_K_V(input_file, key_fields, progress = None):
        """
        å°†sntå½“å‰excelæ–‡ä»¶ä¸­active_sheetä¸­å…³é”®å­—æ®µkeysâ€”â€”ç”¨äºè”ç³»æ•°æ®ï¼Œçš„è¡Œå†™å…¥å†…å­˜{key_tuple,row}
        """
        try:
            output_ws = load_workbook(input_file).active

            snt_data = {}
            snt_gen = ExcelProcessor.excel_row_generator(
                output_ws,
                input_file,
                progress,
                key_fields,
                strict_flag=False
            )
            for row in snt_gen:
                key = tuple(row[field] for field in key_fields)
                if key in snt_data:
                    Logger.info(f"âš ï¸ å‘ç°é‡å¤åŸºå‡†æ•°æ®: {key}")
                snt_data[key] = row

            return snt_data
        except Exception as e:
            raise RuntimeError (f"âŒ å†…å­˜åŠ è½½{input_file}åŸºå‡†æ•°æ®å¤±è´¥: {str(e)}")
    @staticmethod
    def read_excel_row(template_file_name, sheet_name, index, max_retries=3, retry_delay=1):
        """
        è¯»å–Excelæ–‡ä»¶ä¸­æŒ‡å®šå·¥ä½œè¡¨çš„æ•°æ®è¡Œï¼Œå¹¶è¿”å›è¡¨å¤´ä¸æ•°æ®çš„é”®å€¼å¯¹
        
        å‚æ•°:
        template_file_name (str): Excelæ–‡ä»¶å(.xlsxæˆ–.xls)
        sheet_name (str): å·¥ä½œè¡¨åç§°
        index (int): è¦è¯»å–çš„æ•°æ®è¡Œç´¢å¼•(0-based)
        max_retries (int): æœ€å¤§é‡è¯•æ¬¡æ•°(é»˜è®¤3)
        retry_delay (int): é‡è¯•å»¶è¿Ÿæ—¶é—´(ç§’ï¼Œé»˜è®¤1)
        
        è¿”å›:
        dict: åŒ…å«è¡¨å¤´å’Œæ•°æ®é”®å€¼å¯¹çš„å­—å…¸ï¼Œå¤±è´¥æ—¶è¿”å›None
        """
        if not os.path.exists(template_file_name):
            raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {template_file_name}")
        
        for attempt in range(max_retries + 1):
            try:
                # è¯»å–Excelæ–‡ä»¶
                df = pd.read_excel(
                    template_file_name,
                    sheet_name=sheet_name,
                    header=0,  # ä½¿ç”¨ç¬¬ä¸€è¡Œä½œä¸ºåˆ—å
                    dtype=str,   # å°†æ‰€æœ‰æ•°æ®è¯»å–ä¸ºå­—ç¬¦ä¸²ä¿æŒåŸå§‹æ ¼å¼
                    keep_default_na=False  # ç¦ç”¨é»˜è®¤NaNè½¬æ¢
                )
                
                # éªŒè¯è¡Œç´¢å¼•æœ‰æ•ˆæ€§
                if index < 0 or index >= len(df):
                    raise IndexError(f"è¡Œç´¢å¼•{index}è¶…å‡ºèŒƒå›´(0-{len(df)-1})")
                
                # è·å–è¡¨å¤´å’Œè¡Œæ•°æ®
                headers = df.columns.tolist()
                row_values = df.iloc[index].tolist()
                
                # åˆ›å»ºé”®å€¼å¯¹å­—å…¸
                return {str(header): str(value) for header, value in zip(headers, row_values)}
            
            except Exception as e:
                Logger.debug(f"âš ï¸ è¯»å–å¤±è´¥(å°è¯• {attempt+1}/{max_retries}): {str(e)}")
                if attempt < max_retries:
                    Logger.info(f"â³ ç­‰å¾… {retry_delay} ç§’åé‡è¯•...")
                    time.sleep(retry_delay)
                else:
                    Logger.debug(f"âŒ è¯»å–Excelæ–‡ä»¶ä¸­æŒ‡å®šå·¥ä½œè¡¨çš„æ•°æ®è¡Œå¤±è´¥: {str(e)}")
                    return None